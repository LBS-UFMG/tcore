{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ad936c",
   "metadata": {},
   "source": [
    "# Modelo de Predição de Temperatura Interna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe9c04",
   "metadata": {},
   "source": [
    "Organizacao - 1° notebook de modelo de predição de temperatura interna a cada 1 km em corrida autorregulada "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5222714f",
   "metadata": {},
   "source": [
    "Algoritmos:\n",
    "Lasso, Decision tree, Random forest, XGBoost, SVM\n",
    "\n",
    "Apenas o algoritmo Lasso usou escalonamento \n",
    "\n",
    "Dados processados foram divididos em X e y. Depois divididos em 80% 20%. Nos 80% dados foi aplicado GroupKfold == 5. Os 20% restantes foram usados para a validação dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01ac0be",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47a89c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manipulação de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#visualização de dados\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#modelagem e avaliação\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, LeaveOneGroupOut, GroupShuffleSplit, GroupKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa957a2d",
   "metadata": {},
   "source": [
    "### Import database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X \n",
    "X = pd.read_csv('/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/X-data1-1km.csv')\n",
    "\n",
    "#y\n",
    "y = pd.read_csv('/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/y-data1-1km.csv')\n",
    "\n",
    "#grupos\n",
    "groups = pd.read_csv('/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/groups-data1-1km.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e429f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SETS = {\n",
    "    'DS1': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'column_Male','age', 'vo2máx'],\n",
    "    'DS2' : ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed'],\n",
    "    'DS3' : ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed', 'umidade_absoluta', 'dry_temp', 'wet_temp', 'relative_humidity']\n",
    "}\n",
    "\n",
    "groups = groups['trial_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divisao dos dados em treino e tese (Hold-out)\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "y_train = y_train.values.ravel() #transforma em array 1D\n",
    "y_test = y_test.values.ravel() #transforma em array 1D\n",
    "groups_train = groups.iloc[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e69f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definição de hiperparâmetros\n",
    "OPTIMIZED_PARAMS = {\n",
    "    'Lasso': {\n",
    "        'DS1': {'alpha': 0.02868}, \n",
    "        'DS2': {'alpha': 0.02394},\n",
    "        'DS3': {'alpha': 0.02631}\n",
    "    },\n",
    "    'SVR': {\n",
    "        'DS1': {'kernel': 'rbf', 'C': 1.0, 'gamma': 'scale', 'epsilon': 0.1},\n",
    "        'DS2': {'kernel': 'rbf', 'C': 1.0, 'gamma': 'scale', 'epsilon': 0.1},\n",
    "        'DS3': {'kernel': 'rbf', 'C': 1.0, 'gamma': 'scale', 'epsilon': 0.1}\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'DS1': {'max_depth': 10, 'min_samples_leaf': 25, 'min_samples_split': 5},\n",
    "        'DS2': {'max_depth': 10, 'min_samples_leaf': 25, 'min_samples_split': 5},\n",
    "        'DS3': {'max_depth': 10, 'min_samples_leaf': 25, 'min_samples_split': 5}\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'DS1': {'max_features': 0.8, 'max_samples': 0.8, 'min_samples_leaf': 10, 'min_samples_split': 30, 'n_estimators': 200},\n",
    "        'DS2': {'max_features': 0.7, 'max_samples': 0.8, 'min_samples_leaf': 10, 'min_samples_split': 30, 'n_estimators': 200},\n",
    "        'DS3': {'max_features': 0.7, 'max_samples': 0.8, 'min_samples_leaf': 10, 'min_samples_split': 30, 'n_estimators': 400}\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'DS1': {'colsample_bytree': 0.5, 'gamma': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 700, 'reg_alpha': 0.1, 'reg_lambda': 6, 'subsample': 0.5},\n",
    "        'DS2': {'colsample_bytree': 0.5, 'gamma': 1.0, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 500, 'reg_alpha': 0.1, 'reg_lambda': 8, 'subsample': 0.5},\n",
    "        'DS3': {'colsample_bytree': 0.5, 'gamma': 1.0, 'learning_rate': 0.02, 'max_depth': 3, 'n_estimators': 700, 'reg_alpha': 0.1, 'reg_lambda': 8, 'subsample': 0.5}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dbe2dce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a validação cruzada\n",
      "Iniciando Validação Cruzada\n",
      "Validando com o conjunto de features: ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'column_Male', 'age', 'vo2máx']\n",
      "  Treinando modelo: Lasso com escalonamento\n",
      "  Treinando modelo: SVR com escalonamento\n",
      "  Treinando modelo: DecisionTree sem escalonamento\n",
      "  Treinando modelo: RandomForest sem escalonamento\n",
      "  Treinando modelo: XGBoost sem escalonamento\n",
      "Validando com o conjunto de features: ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed']\n",
      "  Treinando modelo: Lasso com escalonamento\n",
      "  Treinando modelo: SVR com escalonamento\n",
      "  Treinando modelo: DecisionTree sem escalonamento\n",
      "  Treinando modelo: RandomForest sem escalonamento\n",
      "  Treinando modelo: XGBoost sem escalonamento\n",
      "Validando com o conjunto de features: ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed', 'umidade_absoluta', 'dry_temp', 'wet_temp', 'relative_humidity']\n",
      "  Treinando modelo: Lasso com escalonamento\n",
      "  Treinando modelo: SVR com escalonamento\n",
      "  Treinando modelo: DecisionTree sem escalonamento\n",
      "  Treinando modelo: RandomForest sem escalonamento\n",
      "  Treinando modelo: XGBoost sem escalonamento\n",
      "Validação Cruzada Concluída\n"
     ]
    }
   ],
   "source": [
    "# execução da validação cruzada nos dados de treino \n",
    "resultados_validacao = []\n",
    "cv_splitter = GroupKFold(n_splits=5)\n",
    "scoring = {\n",
    "    'r2': 'r2', \n",
    "    'rmse': make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)), greater_is_better=False)\n",
    "}\n",
    "\n",
    "print(\"Iniciando a validação cruzada\")\n",
    "\n",
    "\n",
    "scaled_models = ['Lasso', 'SVR']\n",
    "tree_based_models = ['DecisionTree', 'RandomForest', 'XGBoost']\n",
    "\n",
    "print('Iniciando Validação Cruzada')\n",
    "\n",
    "for feature_set_name, feature_list in FEATURE_SETS.items():\n",
    "    print(f'Validando com o conjunto de features: {feature_list}')\n",
    "    X_train_subset = X_train[feature_list]\n",
    "\n",
    "    #modelos que precisam de escalonamento\n",
    "    for model_name in scaled_models:\n",
    "        print(f'  Treinando modelo: {model_name} com escalonamento')\n",
    "        params = OPTIMIZED_PARAMS[model_name][feature_set_name]\n",
    "        \n",
    "        if model_name == 'Lasso':\n",
    "            model_instance = Lasso(random_state=42, max_iter=20000, **params)\n",
    "        elif model_name == 'SVR':\n",
    "            model_instance = SVR(**params)\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', model_instance)\n",
    "        ])\n",
    "\n",
    "        scores = cross_validate(pipeline, X_train_subset, y_train, cv=cv_splitter, scoring=scoring, return_train_score=True, groups=groups_train)\n",
    "        resultados_validacao.append({\n",
    "            'model': model_name,\n",
    "            'feature_set': feature_set_name,\n",
    "            'scaled': True,\n",
    "            'R2_train_cv': np.mean(scores['train_r2']),\n",
    "            'R2_valid_cv': np.mean(scores['test_r2']),\n",
    "            'RMSE_train_cv': -np.mean(scores['train_rmse']),\n",
    "            'RMSE_valid': -np.mean(scores['test_rmse'])\n",
    "\n",
    "        })  \n",
    "\n",
    "\n",
    "    #modelos baseados em árvore que não precisam de escalonamento\n",
    "    for model_name in tree_based_models:\n",
    "        print(f'  Treinando modelo: {model_name} sem escalonamento')\n",
    "        params = OPTIMIZED_PARAMS[model_name][feature_set_name]\n",
    "        if model_name == 'DecisionTree':\n",
    "            model_instance = DecisionTreeRegressor(random_state=42, **params)\n",
    "        elif model_name == 'RandomForest':\n",
    "            model_instance = RandomForestRegressor(random_state=42, **params)\n",
    "        elif model_name == 'XGBoost':\n",
    "            model_instance = xgb.XGBRegressor(random_state=42, objective='reg:squarederror', **params)\n",
    "\n",
    "        scores_unscaled = cross_validate(model_instance, X_train_subset, y_train, cv=cv_splitter, scoring=scoring,groups=groups_train, return_train_score=True)\n",
    "        resultados_validacao.append({\n",
    "            'model': model_name,\n",
    "            'feature_set': feature_set_name,\n",
    "            'scaled': False,\n",
    "            'R2_train_cv': np.mean(scores['train_r2']),\n",
    "            'R2_valid_cv': np.mean(scores['test_r2']),\n",
    "            'RMSE_valid': -np.mean(scores['test_rmse']),\n",
    "            'RMSE_train_cv': -np.mean(scores['train_rmse'])\n",
    "            })\n",
    "\n",
    "print(\"Validação Cruzada Concluída\")\n",
    "results_validation_df = pd.DataFrame(resultados_validacao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "242daf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo da validação cruzada : RandomForest (DS2)\n",
      " - RMSE de validação (media da validação cruzada): 0.5097\n",
      "Resultado final no conjunto de teste:(hold-out):\n",
      " - R²: 0.8582\n",
      " - RMSE: 0.3835\n"
     ]
    }
   ],
   "source": [
    "# selecao e avalicao final no conjunto de teste\n",
    "\n",
    "best_experiment = results_validation_df.sort_values('RMSE_valid').iloc[-1]\n",
    "best_model_name = best_experiment['model']\n",
    "best_feature_set_name = best_experiment['feature_set']\n",
    "best_params = OPTIMIZED_PARAMS[best_model_name][best_feature_set_name]\n",
    "best_was_scaled = best_experiment['scaled']\n",
    "\n",
    "\n",
    "print(f'Melhor modelo da validação cruzada : {best_experiment[\"model\"]} ({best_experiment['feature_set']})')\n",
    "print(f' - RMSE de validação (media da validação cruzada): {best_experiment[\"RMSE_valid\"]:.4f}')\n",
    "\n",
    "\n",
    "best_features = FEATURE_SETS[best_feature_set_name]\n",
    "X_train_best = X_train[best_features]\n",
    "X_test_best = X_test[best_features]\n",
    "\n",
    "\n",
    "\n",
    "# instancia do modelos final\n",
    "if best_model_name == 'Lasso':\n",
    "    final_model = Lasso(random_state=42, max_iter=20000, **best_params)\n",
    "elif best_model_name == 'SVR':\n",
    "    final_model = SVR(**best_params)\n",
    "elif best_model_name == 'DecisionTree':\n",
    "    final_model = DecisionTreeRegressor(random_state=42, **best_params)\n",
    "elif best_model_name == 'RandomForest':\n",
    "    final_model = RandomForestRegressor(random_state=42, **best_params)\n",
    "elif best_model_name == 'XGBoost':  \n",
    "    final_model = xgb.XGBRegressor(random_state=42, objective='reg:squarederror', **best_params)\n",
    "\n",
    "\n",
    "if best_was_scaled:\n",
    "    final_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', final_model)\n",
    "    ])\n",
    "else:\n",
    "    final_pipeline = Pipeline([\n",
    "        ('model', final_model)\n",
    "    ])\n",
    "\n",
    "\n",
    "final_pipeline.fit(X_train_best, y_train)\n",
    "y_test_pred = final_pipeline.predict(X_test_best)  \n",
    "r2_final = r2_score(y_test, y_test_pred)\n",
    "rmse_final = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "print(f'Resultado final no conjunto de teste:(hold-out):')\n",
    "print(f' - R²: {r2_final:.4f}')\n",
    "print(f' - RMSE: {rmse_final:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264bba80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
