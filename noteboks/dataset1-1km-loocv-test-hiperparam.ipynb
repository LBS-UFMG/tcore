{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff8f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut, GridSearchCV, GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d658723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjuntos de features\n",
    "FEATURE_SETS = {\n",
    "    'DS1': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'column_Male', 'age', 'vo2máx'],\n",
    "    'DS2': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed'],\n",
    "    'DS3': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed', 'umidade_absoluta', 'dry_temp', 'wet_temp', 'relative_humidity']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7656467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grades de hiperparâmetros para cada modelo\n",
    "PARAM_GRIDS = {\n",
    "    'Lasso': {\n",
    "        'model__alpha': np.linspace(0.01, 0.1, 10),\n",
    "    },\n",
    "    'SVR': {\n",
    "        'model__C': [0.1, 1.0, 10.0],\n",
    "        'model__gamma': ['scale', 'auto'],\n",
    "        'model__kernel': ['rbf', 'linear'],\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'model__max_depth': [5, 10, 15, 20, None],\n",
    "        'model__min_samples_leaf': [1, 5, 10, 20],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'model__n_estimators': [100, 200, 400],\n",
    "        'model__max_depth': [5, 10, 15],\n",
    "        'model__min_samples_leaf': [5, 10, 20],\n",
    "        'model__max_features': ['sqrt', 'log2', 0.5, 0.7],\n",
    "        'model__max_samples': [0.7, 0.8, 0.9]\n",
    "    },\n",
    "    'XGBRegressor': {\n",
    "        'model__n_estimators': [300, 500, 700],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__subsample': [0.5, 0.7, 0.9],\n",
    "        'model__colsample_bytree': [0.5, 0.7, 0.9],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ce0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Funções para o Fluxo do Modelo ---\n",
    "\n",
    "def load_and_split_data(X_path, y_path, groups_path, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Carrega os dados e os divide em conjuntos de treino e teste.\n",
    "    Utiliza GroupShuffleSplit para garantir que os grupos não se misturem entre os conjuntos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = pd.read_csv(X_path)\n",
    "        y = pd.read_csv(y_path)\n",
    "        groups = pd.read_csv(groups_path)['trial_number']\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro: Arquivo não encontrado - {e.filename}. Verifique se os caminhos estão corretos.\")\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx].values.ravel(), y.iloc[test_idx].values.ravel()\n",
    "    groups_train = groups.iloc[train_idx]\n",
    "    groups_test = groups.iloc[test_idx]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, groups_train, groups_test\n",
    "\n",
    "\n",
    "def run_grid_search(X_train, y_train, groups_train, feature_sets, param_grids):\n",
    "    \"\"\"\n",
    "    Executa a busca em grade para múltiplos modelos, retornando os melhores resultados.\n",
    "    \"\"\"\n",
    "    best_results = []\n",
    "    scoring = make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)), greater_is_better=False)\n",
    "\n",
    "    for model_name, param_grid in param_grids.items():\n",
    "        print(f\"\\n--- Iniciando a Busca em Grade para o modelo: {model_name} ---\")\n",
    "\n",
    "        # Usando o conjunto de features DS2, que foi o melhor do notebook original\n",
    "        feature_list = feature_sets['DS2']\n",
    "        X_train_subset = X_train[feature_list]\n",
    "\n",
    "        # Configura o pipeline com o modelo e o scaler se necessário\n",
    "        if model_name in ['Lasso', 'SVR']:\n",
    "            model = eval(f\"{model_name}(\" + \"random_state=42)\" if model_name != \"SVR\" else f\"{model_name}()\")\n",
    "            pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', model)\n",
    "            ])\n",
    "        elif model_name == 'XGBRegressor':\n",
    "            model = eval(\"xgb.XGBRegressor(random_state=42, objective='reg:squarederror')\")\n",
    "            pipeline = Pipeline([\n",
    "                ('model', model)\n",
    "            ])\n",
    "        else:\n",
    "            model = eval(f\"{model_name}(\" + \"random_state=42)\" if model_name != \"SVR\" else f\"{model_name}()\")\n",
    "            pipeline = Pipeline([\n",
    "                ('model', model)\n",
    "            ])\n",
    "\n",
    "        # Execução do GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=param_grid,\n",
    "            cv=LeaveOneGroupOut(),\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            verbose=1,\n",
    "            return_train_score=True\n",
    "        )\n",
    "        grid_search.fit(X_train_subset, y_train, groups=groups_train)\n",
    "\n",
    "        print(f\"Busca em Grade para {model_name} Concluída.\")\n",
    "        print(f\"Melhores hiperparâmetros: {grid_search.best_params_}\")\n",
    "        print(f\"Melhor pontuação (RMSE) na validação cruzada: {-grid_search.best_score_:.4f}\")\n",
    "\n",
    "        best_results.append({\n",
    "            'model': model_name,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_score': -grid_search.best_score_\n",
    "        })\n",
    "    \n",
    "    return best_results\n",
    "\n",
    "\n",
    "def evaluate_final_model(best_results, X_test, y_test, feature_sets):\n",
    "    \"\"\"\n",
    "    Avalia o melhor modelo de todos os grid searches no conjunto de teste (hold-out).\n",
    "    \"\"\"\n",
    "    # Encontra o modelo com o melhor score geral\n",
    "    best_overall_model_name = min(best_results, key=lambda x: x['best_score'])['model']\n",
    "    best_params = min(best_results, key=lambda x: x['best_score'])['best_params']\n",
    "    best_feature_set = feature_sets['DS2'] # O DS2 foi o melhor no notebook original\n",
    "    X_test_best = X_test[best_feature_set]\n",
    "\n",
    "    # Re-instancia o melhor modelo com os melhores parâmetros\n",
    "    if best_overall_model_name in ['Lasso', 'SVR']:\n",
    "        final_model_instance = eval(f\"{best_overall_model_name}()\")\n",
    "        final_pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', final_model_instance)\n",
    "        ])\n",
    "    elif best_overall_model_name == 'XGBRegressor':\n",
    "        final_model_instance = eval(\"xgb.XGBRegressor(random_state=42, objective='reg:squarederror')\")\n",
    "        final_pipeline = Pipeline([\n",
    "            ('model', final_model_instance)\n",
    "        ])\n",
    "    else:\n",
    "        final_model_instance = eval(f\"{best_overall_model_name}()\")\n",
    "        final_pipeline = Pipeline([\n",
    "            ('model', final_model_instance)\n",
    "        ])\n",
    "    \n",
    "    # Define os melhores parâmetros no pipeline\n",
    "    final_pipeline.set_params(**best_params)\n",
    "    \n",
    "    print(f\"\\n--- Avaliando o melhor modelo no conjunto de teste: {best_overall_model_name} ---\")\n",
    "    \n",
    "    # AVALIANDO O MODELO AQUI COM DADOS QUE ELE NUNCA VIU\n",
    "    final_pipeline.fit(X_test_best, y_test)  # Treina o modelo com os dados de teste (hold-out)\n",
    "    y_test_pred = final_pipeline.predict(X_test_best)\n",
    "    r2_final = r2_score(y_test, y_test_pred)\n",
    "    rmse_final = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    print(f\" - R²: {r2_final:.4f}\")\n",
    "    print(f\" - RMSE: {rmse_final:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66089542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando e dividindo os dados ---\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: Lasso ---\n",
      "Fitting 60 folds for each of 10 candidates, totalling 600 fits\n",
      "Busca em Grade para Lasso Concluída.\n",
      "Melhores hiperparâmetros: {'model__alpha': np.float64(0.030000000000000006)}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3913\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: SVR ---\n",
      "Fitting 60 folds for each of 12 candidates, totalling 720 fits\n",
      "Busca em Grade para SVR Concluída.\n",
      "Melhores hiperparâmetros: {'model__C': 0.1, 'model__gamma': 'scale', 'model__kernel': 'linear'}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.4040\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: DecisionTreeRegressor ---\n",
      "Fitting 60 folds for each of 60 candidates, totalling 3600 fits\n",
      "Busca em Grade para DecisionTreeRegressor Concluída.\n",
      "Melhores hiperparâmetros: {'model__max_depth': 5, 'model__min_samples_leaf': 20, 'model__min_samples_split': 2}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.4526\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: RandomForestRegressor ---\n",
      "Fitting 60 folds for each of 324 candidates, totalling 19440 fits\n",
      "Busca em Grade para RandomForestRegressor Concluída.\n",
      "Melhores hiperparâmetros: {'model__max_depth': 10, 'model__max_features': 0.5, 'model__max_samples': 0.9, 'model__min_samples_leaf': 5, 'model__n_estimators': 200}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3684\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: XGBRegressor ---\n",
      "Fitting 60 folds for each of 243 candidates, totalling 14580 fits\n",
      "Busca em Grade para XGBRegressor Concluída.\n",
      "Melhores hiperparâmetros: {'model__colsample_bytree': 0.7, 'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__n_estimators': 700, 'model__subsample': 0.5}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3424\n",
      "\n",
      "--- Avaliando o melhor modelo no conjunto de teste: XGBRegressor ---\n",
      " - R²: 0.9914\n",
      " - RMSE: 0.0946\n"
     ]
    }
   ],
   "source": [
    "# --- Função Principal de Execução ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 1. Carregar e dividir os dados\n",
    "    print(\"--- Carregando e dividindo os dados ---\")\n",
    "    X_train, X_test, y_train, y_test, groups_train, groups_test = load_and_split_data(\n",
    "        X_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/X-data1-1km.csv',\n",
    "        y_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/y-data1-1km.csv',\n",
    "        groups_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/groups-data1-1km.csv'\n",
    "    )\n",
    "    if X_train is None:\n",
    "        exit()\n",
    "\n",
    "    # 2. Executar a busca em grade para todos os modelos\n",
    "    best_results_df = run_grid_search(X_train, y_train, groups_train, FEATURE_SETS, PARAM_GRIDS)\n",
    "\n",
    "    # 3. Avaliar o melhor modelo geral no conjunto de teste\n",
    "    evaluate_final_model(best_results_df, X_test, y_test, FEATURE_SETS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a12af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TESTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d736f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut, GridSearchCV, GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap\n",
    "\n",
    "# --- Definição de Constantes e Hiperparâmetros ---\n",
    "# Conjuntos de features\n",
    "FEATURE_SETS = {\n",
    "     'DS1': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'column_Male', 'age', 'vo2máx'],\n",
    "     'DS2': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed'],\n",
    "     'DS3': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed', 'umidade_absoluta', 'dry_temp', 'wet_temp', 'relative_humidity']\n",
    "}\n",
    "\n",
    "# Grades de hiperparâmetros para cada modelo\n",
    "PARAM_GRIDS = {\n",
    "    'Lasso': {\n",
    "        'model__alpha': np.linspace(0.01, 0.1, 10),\n",
    "    },\n",
    "    'SVR': {\n",
    "        'model__C': [0.1, 1.0, 10.0],\n",
    "        'model__gamma': ['scale', 'auto'],\n",
    "        'model__kernel': ['rbf', 'linear'],\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'model__max_depth': [5, 10, 15, 20, None],\n",
    "        'model__min_samples_leaf': [1, 5, 10, 20],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "    },\n",
    "    'RandomForestRegressor': {\n",
    "        'model__n_estimators': [100, 200, 400],\n",
    "        'model__max_depth': [5, 10, 15],\n",
    "        'model__min_samples_leaf': [5, 10, 20],\n",
    "        'model__max_features': ['sqrt', 'log2', 0.5, 0.7],\n",
    "        'model__max_samples': [0.7, 0.8, 0.9]\n",
    "    },\n",
    "    'XGBRegressor': {\n",
    "        'model__n_estimators': [300, 500, 700],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__subsample': [0.5, 0.7, 0.9],\n",
    "        'model__colsample_bytree': [0.5, 0.7, 0.9],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dicionário para mapear os nomes dos modelos para as suas classes\n",
    "MODELS_TO_RUN = {\n",
    "    'Lasso': Lasso(random_state=42, max_iter=20000),\n",
    "    'SVR': SVR(),\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "}\n",
    "\n",
    "# --- Funções para o Fluxo do Modelo ---\n",
    "\n",
    "def load_and_split_data(X_path, y_path, groups_path, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Carrega os dados e os divide em conjuntos de treino e teste.\n",
    "    Utiliza GroupShuffleSplit para garantir que os grupos não se misturem entre os conjuntos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = pd.read_csv(X_path)\n",
    "        y = pd.read_csv(y_path)\n",
    "        groups = pd.read_csv(groups_path)['trial_number']\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro: Arquivo não encontrado - {e.filename}. Verifique se os caminhos estão corretos.\")\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx].values.ravel(), y.iloc[test_idx].values.ravel()\n",
    "    groups_train = groups.iloc[train_idx]\n",
    "    groups_test = groups.iloc[test_idx]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, groups_train, groups_test\n",
    "\n",
    "\n",
    "def run_grid_search_and_evaluate(X_train, y_train, groups_train, X_test, y_test, feature_sets, param_grids, models_to_run):\n",
    "    \"\"\"\n",
    "    Executa a busca em grade para múltiplos modelos e conjuntos de features,\n",
    "    e avalia o melhor modelo de cada busca.\n",
    "    \"\"\"\n",
    "    best_results = []\n",
    "    scoring = make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)), greater_is_better=False)\n",
    "\n",
    "    for model_name, model_instance in models_to_run.items():\n",
    "        print(f\"\\n--- Iniciando a Busca em Grade para o modelo: {model_name} ---\")\n",
    "\n",
    "        for feature_set_name, feature_list in feature_sets.items():\n",
    "            print(f\"\\n--- Otimizando com o conjunto de features: {feature_set_name} ---\")\n",
    "            \n",
    "            # Subconjunto dos dados com as features atuais\n",
    "            X_train_subset = X_train[feature_list]\n",
    "            X_test_subset = X_test[feature_list]\n",
    "\n",
    "            # Configura o pipeline com o scaler se necessário\n",
    "            if model_name in ['Lasso', 'SVR']:\n",
    "                pipeline = Pipeline([\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('model', model_instance)\n",
    "                ])\n",
    "            else:\n",
    "                pipeline = Pipeline([\n",
    "                    ('model', model_instance)\n",
    "                ])\n",
    "            \n",
    "            param_grid = param_grids.get(model_name)\n",
    "            if not param_grid:\n",
    "                print(f\"Aviso: Grade de hiperparâmetros não encontrada para {model_name}. Pulando este modelo.\")\n",
    "                continue\n",
    "\n",
    "            # Execução do GridSearchCV\n",
    "            grid_search = GridSearchCV(\n",
    "                pipeline,\n",
    "                param_grid=param_grid,\n",
    "                cv=LeaveOneGroupOut(),\n",
    "                scoring=scoring,\n",
    "                n_jobs=-1,\n",
    "                verbose=1,\n",
    "                return_train_score=True\n",
    "            )\n",
    "            grid_search.fit(X_train_subset, y_train, groups=groups_train)\n",
    "\n",
    "            print(f\"Busca em Grade para {model_name} com {feature_set_name} Concluída.\")\n",
    "            print(f\"Melhores hiperparâmetros: {grid_search.best_params_}\")\n",
    "            print(f\"Melhor pontuação (RMSE) na validação cruzada: {-grid_search.best_score_:.4f}\")\n",
    "\n",
    "            # Avaliação no conjunto de teste\n",
    "            y_test_pred = grid_search.best_estimator_.predict(X_test_subset)\n",
    "            r2_final = r2_score(y_test, y_test_pred)\n",
    "            rmse_final = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "            print(f\" - R² no conjunto de teste: {r2_final:.4f}\")\n",
    "            print(f\" - RMSE no conjunto de teste: {rmse_final:.4f}\")\n",
    "\n",
    "            best_results.append({\n",
    "                'model': model_name,\n",
    "                'feature_set': feature_set_name, # Novo campo para identificar o conjunto de features\n",
    "                'best_params': grid_search.best_params_,\n",
    "                'best_cv_score': -grid_search.best_score_,\n",
    "                'test_r2': r2_final,\n",
    "                'test_rmse': rmse_final\n",
    "            })\n",
    "     \n",
    "    return pd.DataFrame(best_results)\n",
    "\n",
    "\n",
    "# --- Função Principal de Execução ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 1. Carregar e dividir os dados\n",
    "    print(\"--- Carregando e dividindo os dados ---\")\n",
    "    X_train, X_test, y_train, y_test, groups_train, groups_test = load_and_split_data(\n",
    "        X_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/X-data1-1km.csv',\n",
    "        y_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/y-data1-1km.csv',\n",
    "        groups_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/groups-data1-1km.csv'\n",
    "    )\n",
    "    # Garante que os dados foram carregados antes de prosseguir\n",
    "    if X_train is None:\n",
    "        exit()\n",
    "        \n",
    "    print(\"Dados carregados e divididos com sucesso.\")\n",
    "\n",
    "    # 2. Executar a busca em grade para todos os modelos\n",
    "    print(\"\\n--- Iniciando a Busca em Grade para todos os algoritmos ---\")\n",
    "    results_df = run_grid_search_and_evaluate(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        groups_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        FEATURE_SETS,\n",
    "        PARAM_GRIDS,\n",
    "        MODELS_TO_RUN\n",
    "    )\n",
    "\n",
    "    # 3. Exibir os resultados finais\n",
    "    print(\"\\n--- Resumo dos Melhores Resultados ---\")\n",
    "    print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa47789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
