{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dff8f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut, GridSearchCV, GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d658723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjuntos de features\n",
    "FEATURE_SETS = {\n",
    "    'DS1': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'column_Male', 'age', 'vo2máx'],\n",
    "    'DS2': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed'],\n",
    "    'DS3': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed', 'umidade_absoluta', 'dry_temp', 'wet_temp', 'relative_humidity']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7656467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grades de hiperparâmetros para cada modelo\n",
    "PARAM_GRIDS = {\n",
    "    'Lasso': {\n",
    "        'model__alpha': np.linspace(0.01, 0.1, 10),\n",
    "    },\n",
    "    'SVR': {\n",
    "        'model__C': [0.1, 1.0, 10.0],\n",
    "        'model__gamma': ['scale', 'auto'],\n",
    "        'model__kernel': ['rbf', 'linear'],\n",
    "    },\n",
    "    'DecisionTreeRegressor': {\n",
    "        'model__max_depth': [5, 10, 15, 20, None],\n",
    "        'model__min_samples_leaf': [1, 5, 10, 20],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "    },\n",
    "    # 'RandomForestRegressor': {\n",
    "    #     'model__n_estimators': [100, 200, 400],\n",
    "    #     'model__max_depth': [5, 10, 15],\n",
    "    #     'model__min_samples_leaf': [5, 10, 20],\n",
    "    #     'model__max_features': ['sqrt', 'log2', 0.5, 0.7],\n",
    "    #     'model__max_samples': [0.7, 0.8, 0.9]\n",
    "    # },\n",
    "    # 'XGBRegressor': {\n",
    "    #     'model__n_estimators': [300, 500, 700],\n",
    "    #     'model__max_depth': [3, 5, 7],\n",
    "    #     'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    #     'model__subsample': [0.5, 0.7, 0.9],\n",
    "    #     'model__colsample_bytree': [0.5, 0.7, 0.9],\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9ce0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Funções para o Fluxo do Modelo ---\n",
    "\n",
    "def load_and_split_data(X_path, y_path, groups_path, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Carrega os dados e os divide em conjuntos de treino e teste.\n",
    "    Utiliza GroupShuffleSplit para garantir que os grupos não se misturem entre os conjuntos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = pd.read_csv(X_path)\n",
    "        y = pd.read_csv(y_path)\n",
    "        groups = pd.read_csv(groups_path)['trial_number']\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro: Arquivo não encontrado - {e.filename}. Verifique se os caminhos estão corretos.\")\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx].values.ravel(), y.iloc[test_idx].values.ravel()\n",
    "    groups_train = groups.iloc[train_idx]\n",
    "    groups_test = groups.iloc[test_idx]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, groups_train, groups_test\n",
    "\n",
    "\n",
    "def run_grid_search(X_train, y_train, groups_train, feature_sets, param_grids):\n",
    "    \"\"\"\n",
    "    Executa a busca em grade para múltiplos modelos, retornando os melhores resultados.\n",
    "    \"\"\"\n",
    "    best_results = []\n",
    "    scoring = make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)), greater_is_better=False)\n",
    "\n",
    "    for model_name, param_grid in param_grids.items():\n",
    "        print(f\"\\n--- Iniciando a Busca em Grade para o modelo: {model_name} ---\")\n",
    "\n",
    "        # Usando o conjunto de features DS2, que foi o melhor do notebook original\n",
    "        feature_list = feature_sets['DS2']\n",
    "        X_train_subset = X_train[feature_list]\n",
    "\n",
    "        # Configura o pipeline com o modelo e o scaler se necessário\n",
    "        if model_name in ['Lasso', 'SVR']:\n",
    "            model = eval(f\"{model_name}(\" + \"random_state=42)\" if model_name != \"SVR\" else f\"{model_name}()\")\n",
    "            pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', model)\n",
    "            ])\n",
    "        elif model_name == 'XGBRegressor':  \n",
    "            model = xgb.XGBRegressor(random_state=42)\n",
    "            pipeline = Pipeline([\n",
    "                ('model', model)\n",
    "            ])\n",
    "            \n",
    "        else:\n",
    "            model = eval(f\"{model_name}(\" + \"random_state=42)\" if model_name != \"SVR\" else f\"{model_name}()\")\n",
    "            pipeline = Pipeline([\n",
    "                ('model', model)\n",
    "            ])\n",
    "\n",
    "        # Execução do GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=param_grid,\n",
    "            cv=LeaveOneGroupOut(),\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            verbose=1,\n",
    "            return_train_score=True\n",
    "        )\n",
    "        grid_search.fit(X_train_subset, y_train, groups=groups_train)\n",
    "\n",
    "        print(f\"Busca em Grade para {model_name} Concluída.\")\n",
    "        print(f\"Melhores hiperparâmetros: {grid_search.best_params_}\")\n",
    "        print(f\"Melhor pontuação (RMSE) na validação cruzada: {-grid_search.best_score_:.4f}\")\n",
    "\n",
    "        best_results.append({\n",
    "            'model': model_name,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_score': -grid_search.best_score_,\n",
    "            'test_r2': r2_score(y_test, grid_search.best_estimator_.predict(X_test[feature_list])),\n",
    "            'test_rmse': np.sqrt(mean_squared_error(y_test, grid_search.best_estimator_.predict(X_test[feature_list])))\n",
    "        })\n",
    "    \n",
    "    return best_results\n",
    "\n",
    "\n",
    "def evaluate_final_model(best_results, X_test, y_test, feature_sets):\n",
    "    \"\"\"\n",
    "    Avalia o melhor modelo de todos os grid searches no conjunto de teste (hold-out).\n",
    "    \"\"\"\n",
    "    # Encontra o modelo com o melhor score geral\n",
    "    best_overall_model_name = min(best_results, key=lambda x: x['best_score'])['model']\n",
    "    best_params = min(best_results, key=lambda x: x['best_score'])['best_params']\n",
    "    best_feature_set = feature_sets['DS2'] # O DS2 foi o melhor no notebook original\n",
    "    X_test_best = X_test[best_feature_set]\n",
    "\n",
    "    # Re-instancia o melhor modelo com os melhores parâmetros\n",
    "    if best_overall_model_name in ['Lasso', 'SVR']:\n",
    "        final_model_instance = eval(f\"{best_overall_model_name}()\")\n",
    "        final_pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', final_model_instance)\n",
    "        ])\n",
    "    elif best_overall_model_name == 'XGBRegressor':\n",
    "        final_model_instance = xgb.XGBRegressor(random_state=42)\n",
    "        final_pipeline = Pipeline([\n",
    "            ('model', final_model_instance)\n",
    "        ])  \n",
    "\n",
    "    else:\n",
    "        final_model_instance = eval(f\"{best_overall_model_name}()\")\n",
    "        final_pipeline = Pipeline([\n",
    "            ('model', final_model_instance)\n",
    "        ])\n",
    "    \n",
    "    # Define os melhores parâmetros no pipeline\n",
    "    final_pipeline.set_params(**best_params)\n",
    "    \n",
    "    print(f\"\\n--- Avaliando o melhor modelo no conjunto de teste: {best_overall_model_name} ---\")\n",
    "    \n",
    "    # AVALIANDO O MODELO AQUI COM DADOS QUE ELE NUNCA VIU\n",
    "    final_pipeline.fit(X_test_best, y_test)  # Treina o modelo com os dados de teste (hold-out)\n",
    "    y_test_pred = final_pipeline.predict(X_test_best)\n",
    "    r2_final = r2_score(y_test, y_test_pred)\n",
    "    rmse_final = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    print(f\" - R²: {r2_final:.4f}\")\n",
    "    print(f\" - RMSE: {rmse_final:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66089542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando e dividindo os dados ---\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: Lasso ---\n",
      "Fitting 60 folds for each of 10 candidates, totalling 600 fits\n",
      "Busca em Grade para Lasso Concluída.\n",
      "Melhores hiperparâmetros: {'model__alpha': np.float64(0.030000000000000006)}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3913\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: SVR ---\n",
      "Fitting 60 folds for each of 12 candidates, totalling 720 fits\n",
      "Busca em Grade para SVR Concluída.\n",
      "Melhores hiperparâmetros: {'model__C': 0.1, 'model__gamma': 'scale', 'model__kernel': 'linear'}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.4040\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: DecisionTreeRegressor ---\n",
      "Fitting 60 folds for each of 60 candidates, totalling 3600 fits\n",
      "Busca em Grade para DecisionTreeRegressor Concluída.\n",
      "Melhores hiperparâmetros: {'model__max_depth': 5, 'model__min_samples_leaf': 20, 'model__min_samples_split': 2}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.4526\n",
      "\n",
      "--- Avaliando o melhor modelo no conjunto de teste: Lasso ---\n",
      " - R²: 0.8983\n",
      " - RMSE: 0.3248\n",
      "                   model                                        best_params  \\\n",
      "0                  Lasso             {'model__alpha': 0.030000000000000006}   \n",
      "1                    SVR  {'model__C': 0.1, 'model__gamma': 'scale', 'mo...   \n",
      "2  DecisionTreeRegressor  {'model__max_depth': 5, 'model__min_samples_le...   \n",
      "\n",
      "   best_score   test_r2  test_rmse  \n",
      "0    0.391299  0.848336   0.396613  \n",
      "1    0.403991  0.854007   0.389127  \n",
      "2    0.452605  0.822507   0.429058  \n"
     ]
    }
   ],
   "source": [
    "# --- Função Principal de Execução ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 1. Carregar e dividir os dados\n",
    "    print(\"--- Carregando e dividindo os dados ---\")\n",
    "    X_train, X_test, y_train, y_test, groups_train, groups_test = load_and_split_data(\n",
    "        X_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/X-data1-1km.csv',\n",
    "        y_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/y-data1-1km.csv',\n",
    "        groups_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/groups-data1-1km.csv'\n",
    "    )\n",
    "    if X_train is None:\n",
    "        exit()\n",
    "\n",
    "    # 2. Executar a busca em grade para todos os modelos\n",
    "    best_results_df = run_grid_search(X_train, y_train, groups_train, FEATURE_SETS, PARAM_GRIDS)\n",
    "\n",
    "    # 3. Avaliar o melhor modelo geral no conjunto de teste\n",
    "    evaluate_final_model(best_results_df, X_test, y_test, FEATURE_SETS)\n",
    "    \n",
    "    # 4. Exibir os resultados finais\n",
    "    results_df = pd.DataFrame(best_results_df)\n",
    "\n",
    "\n",
    "\n",
    "    print(results_df)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a12af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TESTE\n",
    "\n",
    "\n",
    "# a diferença entre os modelos superior e inferior é de que no inferior, os modelos sao otimizados para cada data set poposto\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d736f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando e dividindo os dados ---\n",
      "Dados carregados e divididos com sucesso.\n",
      "\n",
      "--- Iniciando a Busca em Grade para todos os algoritmos ---\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: Lasso ---\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS1 ---\n",
      "Fitting 60 folds for each of 10 candidates, totalling 600 fits\n",
      "Busca em Grade para Lasso com DS1 Concluída.\n",
      "Melhores hiperparâmetros: {'model__alpha': np.float64(0.030000000000000006)}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3899\n",
      " - R² no conjunto de teste: 0.8404\n",
      " - RMSE no conjunto de teste: 0.4068\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS2 ---\n",
      "Fitting 60 folds for each of 10 candidates, totalling 600 fits\n",
      "Busca em Grade para Lasso com DS2 Concluída.\n",
      "Melhores hiperparâmetros: {'model__alpha': np.float64(0.030000000000000006)}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3913\n",
      " - R² no conjunto de teste: 0.8483\n",
      " - RMSE no conjunto de teste: 0.3966\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS3 ---\n",
      "Fitting 60 folds for each of 10 candidates, totalling 600 fits\n",
      "Busca em Grade para Lasso com DS3 Concluída.\n",
      "Melhores hiperparâmetros: {'model__alpha': np.float64(0.030000000000000006)}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3919\n",
      " - R² no conjunto de teste: 0.8492\n",
      " - RMSE no conjunto de teste: 0.3955\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: SVR ---\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS1 ---\n",
      "Fitting 60 folds for each of 8 candidates, totalling 480 fits\n",
      "Busca em Grade para SVR com DS1 Concluída.\n",
      "Melhores hiperparâmetros: {'model__C': 0.1, 'model__gamma': 'scale', 'model__kernel': 'linear'}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.4024\n",
      " - R² no conjunto de teste: 0.8343\n",
      " - RMSE no conjunto de teste: 0.4145\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS2 ---\n",
      "Fitting 60 folds for each of 8 candidates, totalling 480 fits\n",
      "Busca em Grade para SVR com DS2 Concluída.\n",
      "Melhores hiperparâmetros: {'model__C': 0.1, 'model__gamma': 'scale', 'model__kernel': 'linear'}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.4040\n",
      " - R² no conjunto de teste: 0.8540\n",
      " - RMSE no conjunto de teste: 0.3891\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS3 ---\n",
      "Fitting 60 folds for each of 8 candidates, totalling 480 fits\n",
      "Busca em Grade para SVR com DS3 Concluída.\n",
      "Melhores hiperparâmetros: {'model__C': 0.1, 'model__gamma': 'scale', 'model__kernel': 'linear'}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.4132\n",
      " - R² no conjunto de teste: 0.8545\n",
      " - RMSE no conjunto de teste: 0.3885\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: DecisionTree ---\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS1 ---\n",
      "Fitting 60 folds for each of 8 candidates, totalling 480 fits\n",
      "Busca em Grade para DecisionTree com DS1 Concluída.\n",
      "Melhores hiperparâmetros: {'model__max_depth': 10, 'model__min_samples_leaf': 5, 'model__min_samples_split': 2}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.4564\n",
      " - R² no conjunto de teste: 0.8126\n",
      " - RMSE no conjunto de teste: 0.4409\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS2 ---\n",
      "Fitting 60 folds for each of 8 candidates, totalling 480 fits\n",
      "Busca em Grade para DecisionTree com DS2 Concluída.\n",
      "Melhores hiperparâmetros: {'model__max_depth': 5, 'model__min_samples_leaf': 5, 'model__min_samples_split': 2}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.4611\n",
      " - R² no conjunto de teste: 0.8149\n",
      " - RMSE no conjunto de teste: 0.4382\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS3 ---\n",
      "Fitting 60 folds for each of 8 candidates, totalling 480 fits\n",
      "Busca em Grade para DecisionTree com DS3 Concluída.\n",
      "Melhores hiperparâmetros: {'model__max_depth': 5, 'model__min_samples_leaf': 5, 'model__min_samples_split': 2}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.4611\n",
      " - R² no conjunto de teste: 0.8045\n",
      " - RMSE no conjunto de teste: 0.4503\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: RandomForest ---\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS1 ---\n",
      "Fitting 60 folds for each of 4 candidates, totalling 240 fits\n",
      "Busca em Grade para RandomForest com DS1 Concluída.\n",
      "Melhores hiperparâmetros: {'model__max_depth': 10, 'model__n_estimators': 200}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3674\n",
      " - R² no conjunto de teste: 0.8735\n",
      " - RMSE no conjunto de teste: 0.3622\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS2 ---\n",
      "Fitting 60 folds for each of 4 candidates, totalling 240 fits\n",
      "Busca em Grade para RandomForest com DS2 Concluída.\n",
      "Melhores hiperparâmetros: {'model__max_depth': 10, 'model__n_estimators': 200}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3691\n",
      " - R² no conjunto de teste: 0.8767\n",
      " - RMSE no conjunto de teste: 0.3577\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS3 ---\n",
      "Fitting 60 folds for each of 4 candidates, totalling 240 fits\n",
      "Busca em Grade para RandomForest com DS3 Concluída.\n",
      "Melhores hiperparâmetros: {'model__max_depth': 10, 'model__n_estimators': 200}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3732\n",
      " - R² no conjunto de teste: 0.8768\n",
      " - RMSE no conjunto de teste: 0.3574\n",
      "\n",
      "--- Iniciando a Busca em Grade para o modelo: XGBoost ---\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS1 ---\n",
      "Fitting 60 folds for each of 9 candidates, totalling 540 fits\n",
      "Busca em Grade para XGBoost com DS1 Concluída.\n",
      "Melhores hiperparâmetros: {'model__max_depth': 5, 'model__n_estimators': 300}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3889\n",
      " - R² no conjunto de teste: 0.8494\n",
      " - RMSE no conjunto de teste: 0.3952\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS2 ---\n",
      "Fitting 60 folds for each of 9 candidates, totalling 540 fits\n",
      "Busca em Grade para XGBoost com DS2 Concluída.\n",
      "Melhores hiperparâmetros: {'model__max_depth': 5, 'model__n_estimators': 300}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3804\n",
      " - R² no conjunto de teste: 0.8310\n",
      " - RMSE no conjunto de teste: 0.4187\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS3 ---\n",
      "Fitting 60 folds for each of 9 candidates, totalling 540 fits\n",
      "Busca em Grade para XGBoost com DS3 Concluída.\n",
      "Melhores hiperparâmetros: {'model__max_depth': 5, 'model__n_estimators': 300}\n",
      "Melhor pontuação (RMSE) na validação cruzada: 0.3750\n",
      " - R² no conjunto de teste: 0.8424\n",
      " - RMSE no conjunto de teste: 0.4044\n",
      "\n",
      "--- Resultados da Busca em Grade Concluída ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_cv_score</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>train_r2</th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>train_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>DS1</td>\n",
       "      <td>{'model__alpha': 0.030000000000000006}</td>\n",
       "      <td>0.3899</td>\n",
       "      <td>0.8404</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.4068</td>\n",
       "      <td>0.4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>DS2</td>\n",
       "      <td>{'model__alpha': 0.030000000000000006}</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.8483</td>\n",
       "      <td>0.8119</td>\n",
       "      <td>0.3966</td>\n",
       "      <td>0.4074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>DS3</td>\n",
       "      <td>{'model__alpha': 0.030000000000000006}</td>\n",
       "      <td>0.3919</td>\n",
       "      <td>0.8492</td>\n",
       "      <td>0.8123</td>\n",
       "      <td>0.3955</td>\n",
       "      <td>0.4069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>DS1</td>\n",
       "      <td>{'model__C': 0.1, 'model__gamma': 'scale', 'mo...</td>\n",
       "      <td>0.4024</td>\n",
       "      <td>0.8343</td>\n",
       "      <td>0.8107</td>\n",
       "      <td>0.4145</td>\n",
       "      <td>0.4086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVR</td>\n",
       "      <td>DS2</td>\n",
       "      <td>{'model__C': 0.1, 'model__gamma': 'scale', 'mo...</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>0.3891</td>\n",
       "      <td>0.4035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR</td>\n",
       "      <td>DS3</td>\n",
       "      <td>{'model__C': 0.1, 'model__gamma': 'scale', 'mo...</td>\n",
       "      <td>0.4132</td>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.8151</td>\n",
       "      <td>0.3885</td>\n",
       "      <td>0.4038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>DS1</td>\n",
       "      <td>{'model__max_depth': 10, 'model__min_samples_l...</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>0.9181</td>\n",
       "      <td>0.4409</td>\n",
       "      <td>0.2687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>DS2</td>\n",
       "      <td>{'model__max_depth': 5, 'model__min_samples_le...</td>\n",
       "      <td>0.4611</td>\n",
       "      <td>0.8149</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.4382</td>\n",
       "      <td>0.3561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>DS3</td>\n",
       "      <td>{'model__max_depth': 5, 'model__min_samples_le...</td>\n",
       "      <td>0.4611</td>\n",
       "      <td>0.8045</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.3561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>DS1</td>\n",
       "      <td>{'model__max_depth': 10, 'model__n_estimators'...</td>\n",
       "      <td>0.3674</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>0.9763</td>\n",
       "      <td>0.3622</td>\n",
       "      <td>0.1447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>DS2</td>\n",
       "      <td>{'model__max_depth': 10, 'model__n_estimators'...</td>\n",
       "      <td>0.3691</td>\n",
       "      <td>0.8767</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.3577</td>\n",
       "      <td>0.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>DS3</td>\n",
       "      <td>{'model__max_depth': 10, 'model__n_estimators'...</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>0.3574</td>\n",
       "      <td>0.1423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>DS1</td>\n",
       "      <td>{'model__max_depth': 5, 'model__n_estimators':...</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.8494</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3952</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>DS2</td>\n",
       "      <td>{'model__max_depth': 5, 'model__n_estimators':...</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4187</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>DS3</td>\n",
       "      <td>{'model__max_depth': 5, 'model__n_estimators':...</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.8424</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4044</td>\n",
       "      <td>0.0018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model feature_set  \\\n",
       "0          Lasso         DS1   \n",
       "1          Lasso         DS2   \n",
       "2          Lasso         DS3   \n",
       "3            SVR         DS1   \n",
       "4            SVR         DS2   \n",
       "5            SVR         DS3   \n",
       "6   DecisionTree         DS1   \n",
       "7   DecisionTree         DS2   \n",
       "8   DecisionTree         DS3   \n",
       "9   RandomForest         DS1   \n",
       "10  RandomForest         DS2   \n",
       "11  RandomForest         DS3   \n",
       "12       XGBoost         DS1   \n",
       "13       XGBoost         DS2   \n",
       "14       XGBoost         DS3   \n",
       "\n",
       "                                          best_params  best_cv_score  test_r2  \\\n",
       "0              {'model__alpha': 0.030000000000000006}         0.3899   0.8404   \n",
       "1              {'model__alpha': 0.030000000000000006}         0.3913   0.8483   \n",
       "2              {'model__alpha': 0.030000000000000006}         0.3919   0.8492   \n",
       "3   {'model__C': 0.1, 'model__gamma': 'scale', 'mo...         0.4024   0.8343   \n",
       "4   {'model__C': 0.1, 'model__gamma': 'scale', 'mo...         0.4040   0.8540   \n",
       "5   {'model__C': 0.1, 'model__gamma': 'scale', 'mo...         0.4132   0.8545   \n",
       "6   {'model__max_depth': 10, 'model__min_samples_l...         0.4564   0.8126   \n",
       "7   {'model__max_depth': 5, 'model__min_samples_le...         0.4611   0.8149   \n",
       "8   {'model__max_depth': 5, 'model__min_samples_le...         0.4611   0.8045   \n",
       "9   {'model__max_depth': 10, 'model__n_estimators'...         0.3674   0.8735   \n",
       "10  {'model__max_depth': 10, 'model__n_estimators'...         0.3691   0.8767   \n",
       "11  {'model__max_depth': 10, 'model__n_estimators'...         0.3732   0.8768   \n",
       "12  {'model__max_depth': 5, 'model__n_estimators':...         0.3889   0.8494   \n",
       "13  {'model__max_depth': 5, 'model__n_estimators':...         0.3804   0.8310   \n",
       "14  {'model__max_depth': 5, 'model__n_estimators':...         0.3750   0.8424   \n",
       "\n",
       "    train_r2  test_rmse  train_rmse  \n",
       "0     0.8098     0.4068      0.4096  \n",
       "1     0.8119     0.3966      0.4074  \n",
       "2     0.8123     0.3955      0.4069  \n",
       "3     0.8107     0.4145      0.4086  \n",
       "4     0.8154     0.3891      0.4035  \n",
       "5     0.8151     0.3885      0.4038  \n",
       "6     0.9181     0.4409      0.2687  \n",
       "7     0.8562     0.4382      0.3561  \n",
       "8     0.8562     0.4503      0.3561  \n",
       "9     0.9763     0.3622      0.1447  \n",
       "10    0.9768     0.3577      0.1429  \n",
       "11    0.9771     0.3574      0.1423  \n",
       "12    1.0000     0.3952      0.0025  \n",
       "13    1.0000     0.4187      0.0019  \n",
       "14    1.0000     0.4044      0.0018  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importação de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut, GridSearchCV, GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap\n",
    "\n",
    "# --- Definição de Constantes e Hiperparâmetros ---\n",
    "# Conjuntos de features\n",
    "FEATURE_SETS = {\n",
    "    'DS1': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'column_Male', 'age', 'vo2máx'],\n",
    "    'DS2': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed'],\n",
    "    'DS3': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed', 'umidade_absoluta', 'dry_temp', 'wet_temp', 'relative_humidity']\n",
    "}\n",
    "\n",
    "# Grades de hiperparâmetros para cada modelo\n",
    "PARAM_GRIDS = {\n",
    "    'Lasso': {\n",
    "        'model__alpha': np.linspace(0.01, 0.1, 10),\n",
    "    },\n",
    "    'SVR': {\n",
    "        'model__C': [0.1, 1.0],\n",
    "        'model__gamma': ['scale', 'auto'],\n",
    "        'model__kernel': ['rbf', 'linear'],\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'model__max_depth': [5, 10],\n",
    "        'model__min_samples_leaf': [1, 5],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [5, 10],\n",
    "        # 'model__min_samples_leaf': [5, 10, 20],\n",
    "        # 'model__max_features': ['sqrt', 'log2', 0.5, 0.7],\n",
    "        # 'model__max_samples': [0.7, 0.8, 0.9]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model__n_estimators': [300, 500, 700],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        # 'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        # 'model__subsample': [0.5, 0.7, 0.9],\n",
    "        # 'model__colsample_bytree': [0.5, 0.7, 0.9],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dicionário para mapear os nomes dos modelos para as suas classes\n",
    "MODELS_TO_RUN = {\n",
    "    'Lasso': Lasso(random_state=42, max_iter=20000),\n",
    "    'SVR': SVR(),\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "}\n",
    "\n",
    "# --- Funções para o Fluxo do Modelo ---\n",
    "\n",
    "def load_and_split_data(X_path, y_path, groups_path, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Carrega os dados e os divide em conjuntos de treino e teste.\n",
    "    Utiliza GroupShuffleSplit para garantir que os grupos não se misturem entre os conjuntos.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = pd.read_csv(X_path)\n",
    "        y = pd.read_csv(y_path)\n",
    "        groups = pd.read_csv(groups_path)['trial_number']\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro: Arquivo não encontrado - {e.filename}. Verifique se os caminhos estão corretos.\")\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups=groups))\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx].values.ravel(), y.iloc[test_idx].values.ravel()\n",
    "    groups_train = groups.iloc[train_idx]\n",
    "    groups_test = groups.iloc[test_idx]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, groups_train, groups_test\n",
    "\n",
    "\n",
    "def run_grid_search_and_evaluate(X_train, y_train, groups_train, X_test, y_test, feature_sets, param_grids, models_to_run):\n",
    "    \"\"\"\n",
    "    Executa a busca em grade para múltiplos modelos e conjuntos de features,\n",
    "    e avalia o melhor modelo de cada busca.\n",
    "    \"\"\"\n",
    "    best_results = []\n",
    "    scoring = make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)), greater_is_better=False)\n",
    "\n",
    "    for model_name, model_instance in models_to_run.items():\n",
    "        print(f\"\\n--- Iniciando a Busca em Grade para o modelo: {model_name} ---\")\n",
    "\n",
    "        for feature_set_name, feature_list in feature_sets.items():\n",
    "            print(f\"\\n--- Otimizando com o conjunto de features: {feature_set_name} ---\")\n",
    "            \n",
    "            # Subconjunto dos dados com as features atuais\n",
    "            X_train_subset = X_train[feature_list]\n",
    "            X_test_subset = X_test[feature_list]\n",
    "\n",
    "            # Configura o pipeline com o scaler se necessário\n",
    "            if model_name in ['Lasso', 'SVR']:\n",
    "                pipeline = Pipeline([\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('model', model_instance)\n",
    "                ])\n",
    "            else:\n",
    "                pipeline = Pipeline([\n",
    "                    ('model', model_instance)\n",
    "                ])\n",
    "            \n",
    "            param_grid = param_grids.get(model_name)\n",
    "            if not param_grid:\n",
    "                print(f\"Aviso: Grade de hiperparâmetros não encontrada para {model_name}. Pulando este modelo.\")\n",
    "                continue\n",
    "\n",
    "            # Execução do GridSearchCV\n",
    "            grid_search = GridSearchCV(\n",
    "                pipeline,\n",
    "                param_grid=param_grid,\n",
    "                cv=LeaveOneGroupOut(),\n",
    "                scoring=scoring,\n",
    "                n_jobs=-1,\n",
    "                verbose=1,\n",
    "                return_train_score=True\n",
    "            )\n",
    "            grid_search.fit(X_train_subset, y_train, groups=groups_train)\n",
    "\n",
    "            print(f\"Busca em Grade para {model_name} com {feature_set_name} Concluída.\")\n",
    "            print(f\"Melhores hiperparâmetros: {grid_search.best_params_}\")\n",
    "            print(f\"Melhor pontuação (RMSE) na validação cruzada: {-grid_search.best_score_:.4f}\")\n",
    "\n",
    "            # Avaliação no conjunto de teste\n",
    "            y_test_pred = grid_search.best_estimator_.predict(X_test_subset)\n",
    "            r2_final = r2_score(y_test, y_test_pred)\n",
    "            rmse_final = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "            print(f\" - R² no conjunto de teste: {r2_final:.4f}\")\n",
    "            print(f\" - RMSE no conjunto de teste: {rmse_final:.4f}\")\n",
    "\n",
    "             # Avaliação no conjunto de treino\n",
    "            y_train_pred = grid_search.best_estimator_.predict(X_train_subset)\n",
    "            r2_train = r2_score(y_train, y_train_pred)\n",
    "            rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "            # Avaliação no conjunto de teste\n",
    "            y_test_pred = grid_search.best_estimator_.predict(X_test_subset)\n",
    "            r2_final = r2_score(y_test, y_test_pred)\n",
    "            rmse_final = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "            best_results.append({\n",
    "                'model': model_name,\n",
    "                'feature_set': feature_set_name, # Novo campo para identificar o conjunto de features\n",
    "                'best_params': grid_search.best_params_,\n",
    "                'best_cv_score': -grid_search.best_score_,\n",
    "                'test_r2': r2_final,\n",
    "                'train_r2': r2_train,           # <-- NOVO\n",
    "                'test_rmse': rmse_final,\n",
    "                'train_rmse': rmse_train       # <-- NOVO\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(best_results)\n",
    "\n",
    "\n",
    "# --- Função Principal de Execução ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 1. Carregar e dividir os dados\n",
    "    print(\"--- Carregando e dividindo os dados ---\")\n",
    "    X_train, X_test, y_train, y_test, groups_train, groups_test = load_and_split_data(\n",
    "        X_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/X-data1-1km.csv',\n",
    "        y_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/y-data1-1km.csv',\n",
    "        groups_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/groups-data1-1km.csv'\n",
    "    )\n",
    "    # Garante que os dados foram carregados antes de prosseguir\n",
    "    if X_train is None:\n",
    "        exit()\n",
    "        \n",
    "    print(\"Dados carregados e divididos com sucesso.\")\n",
    "\n",
    "    # 2. Executar a busca em grade para todos os modelos\n",
    "    print(\"\\n--- Iniciando a Busca em Grade para todos os algoritmos ---\")\n",
    "    results_df = run_grid_search_and_evaluate(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        groups_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        FEATURE_SETS,\n",
    "        PARAM_GRIDS,\n",
    "        MODELS_TO_RUN\n",
    "    )\n",
    "    print(\"\\n--- Resultados da Busca em Grade Concluída ---\") \n",
    "    # 3. Exibir os resultados finais\n",
    "    display(results_df.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cedb19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
