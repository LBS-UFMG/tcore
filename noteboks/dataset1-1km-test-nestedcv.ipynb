{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdbedb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando os dados ---\n",
      "Dados carregados com sucesso.\n",
      "\n",
      "--- Iniciando o Nested Cross-Validation para todos os algoritmos ---\n",
      "\n",
      "--- Iniciando Nested CV para o modelo: Lasso ---\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS1 ---\n",
      "--- Resultado Final do Nested CV para Lasso com DS1 ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'std_rmse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 210\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# 2. Executar o Nested CV\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Iniciando o Nested Cross-Validation para todos os algoritmos ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m results_df = \u001b[43mrun_nested_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mFEATURE_SETS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mPARAM_GRIDS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMODELS_TO_RUN\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m# 3. Exibir os resultados finais\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Resumo dos Resultados do Nested CV ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 178\u001b[39m, in \u001b[36mrun_nested_cv\u001b[39m\u001b[34m(X, y, groups, feature_sets, param_grids, models_to_run)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m#std_r2 = np.std(test_r2_scores)\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Resultado Final do Nested CV para \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m com \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_set_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  > RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_rmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m +/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mstd_rmse\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    179\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  > R²: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_r2\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m +/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstd_r2\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    181\u001b[39m final_results.append({\n\u001b[32m    182\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: model_name,\n\u001b[32m    183\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeature_set\u001b[39m\u001b[33m'\u001b[39m: feature_set_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mstd_r2\u001b[39m\u001b[33m'\u001b[39m: std_r2\n\u001b[32m    188\u001b[39m })\n",
      "\u001b[31mNameError\u001b[39m: name 'std_rmse' is not defined"
     ]
    }
   ],
   "source": [
    "# Importação de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GridSearchCV, GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib # Para salvar o melhor modelo\n",
    "import shap # Mantido para a próxima etapa de análise\n",
    "\n",
    "# --- Definição de Constantes e Hiperparâmetros ---\n",
    "# Conjuntos de features\n",
    "FEATURE_SETS = {\n",
    "    'DS1': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'column_Male', 'age', 'vo2máx'],\n",
    "    'DS2': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed'],\n",
    "    'DS3': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed', 'umidade_absoluta', 'dry_temp', 'wet_temp', 'relative_humidity']\n",
    "}\n",
    "\n",
    "# Grades de hiperparâmetros para cada modelo\n",
    "PARAM_GRIDS = {\n",
    "    'Lasso': {\n",
    "        'model__alpha': np.linspace(0.01, 0.1, 10),\n",
    "    },\n",
    "    'SVR': {\n",
    "        'model__C': [0.1, 1.0, 10.0],\n",
    "        'model__gamma': ['scale', 'auto'],\n",
    "        'model__kernel': ['rbf', 'linear'],\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'model__max_depth': [5, 10, 15],\n",
    "        'model__min_samples_leaf': [1, 5],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "    },\n",
    "    # 'RandomForest': {\n",
    "    #     'model__n_estimators': [100, 200, 400],\n",
    "    #     'model__max_depth': [5, 10, 15],\n",
    "    #     'model__min_samples_leaf': [5, 10, 20],\n",
    "    #     'model__max_features': ['sqrt', 'log2', 0.5, 0.7],\n",
    "    #     'model__max_samples': [0.7, 0.8, 0.9]\n",
    "    # },\n",
    "    # 'XGBoost': {\n",
    "    #     'model__n_estimators': [300, 500, 700],\n",
    "    #     'model__max_depth': [3, 5, 7],\n",
    "    #     'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    #     'model__subsample': [0.5, 0.7, 0.9],\n",
    "    #     'model__colsample_bytree': [0.5, 0.7, 0.9],\n",
    "    # }\n",
    "}\n",
    "\n",
    "# Dicionário para mapear os nomes dos modelos para as suas classes\n",
    "MODELS_TO_RUN = {\n",
    "    'Lasso': Lasso(random_state=42, max_iter=20000),\n",
    "    'SVR': SVR(),\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "}\n",
    "\n",
    "# --- Funções para o Fluxo do Modelo ---\n",
    "\n",
    "def load_data(X_path, y_path, groups_path):\n",
    "    \"\"\"\n",
    "    Carrega os dados e realiza uma verificação inicial.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = pd.read_csv(X_path)\n",
    "        y = pd.read_csv(y_path)\n",
    "        groups = pd.read_csv(groups_path)['trial_number']\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro: Arquivo não encontrado - {e.filename}.\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Verificação de valores ausentes\n",
    "    if X.isnull().sum().sum() > 0 or y.isnull().sum().sum() > 0:\n",
    "        print(\"Aviso: Dados contêm valores ausentes (NaN). Considere o pré-processamento para tratá-los.\")\n",
    "\n",
    "    return X, y, groups\n",
    "\n",
    "def run_nested_cv(X, y, groups, feature_sets, param_grids, models_to_run):\n",
    "    \"\"\"\n",
    "    Executa a Validação Cruzada Aninhada para múltiplos modelos,\n",
    "    garantindo a separação de grupos e pré-processamento adequado.\n",
    "    \"\"\"\n",
    "    final_results = []\n",
    "\n",
    "    # Loop Externo (para a avaliação final do desempenho)\n",
    "    # GroupShuffleSplit divide os dados em folds independentes por grupo.\n",
    "    outer_cv = GroupShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Loop Interno (para a busca de hiperparâmetros)\n",
    "    # LeaveOneGroupOut garante que um grupo inteiro seja usado para validação.\n",
    "    inner_cv = LeaveOneGroupOut()\n",
    "\n",
    "    for model_name, model_instance in models_to_run.items():\n",
    "        print(f\"\\n--- Iniciando Nested CV para o modelo: {model_name} ---\")\n",
    "\n",
    "        for feature_set_name, feature_list in feature_sets.items():\n",
    "            print(f\"\\n--- Otimizando com o conjunto de features: {feature_set_name} ---\")\n",
    "\n",
    "            test_rmse_scores = []\n",
    "            test_r2_scores = []\n",
    "\n",
    "            # Cria o pré-processador para o pipeline.\n",
    "            # O ColumnTransformer aplica transformações seletivas por tipo de coluna,\n",
    "            # evitando vazamento de dados de escalonamento para variáveis não numéricas.\n",
    "            numeric_features = X[feature_list].select_dtypes(include=np.number).columns\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('scaler', StandardScaler(), numeric_features)\n",
    "                ],\n",
    "                remainder='passthrough'\n",
    "            )\n",
    "\n",
    "            # Configura o pipeline com ou sem o pré-processador, dependendo do modelo.\n",
    "            if model_name in ['Lasso', 'SVR']:\n",
    "                pipeline = Pipeline([\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('model', model_instance)\n",
    "                ])\n",
    "            else:\n",
    "                pipeline = Pipeline([\n",
    "                    ('model', model_instance)\n",
    "                ])\n",
    "\n",
    "            param_grid = param_grids.get(model_name)\n",
    "            if not param_grid:\n",
    "                print(f\"Aviso: Grade de hiperparâmetros não encontrada para {model_name}. Pulando este conjunto.\")\n",
    "                continue\n",
    "\n",
    "            # Loop externo: dividindo o conjunto em treino/validação e teste\n",
    "            for i, (train_val_idx, test_idx) in enumerate(outer_cv.split(X, y, groups=groups)):\n",
    "                # Subconjuntos de dados para o fold atual\n",
    "                X_train_val = X.iloc[train_val_idx][feature_list]\n",
    "                y_train_val = y.iloc[train_val_idx].values.ravel()\n",
    "                groups_train_val = groups.iloc[train_val_idx]\n",
    "\n",
    "                X_test = X.iloc[test_idx][feature_list]\n",
    "                y_test = y.iloc[test_idx].values.ravel()\n",
    "\n",
    "                # Loop interno: GridSearchCV\n",
    "                grid_search = GridSearchCV(\n",
    "                    pipeline,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=inner_cv,\n",
    "                    # Usando a métrica nativa neg_root_mean_squared_error\n",
    "                    scoring='neg_root_mean_squared_error',\n",
    "                    n_jobs=-1,\n",
    "                    verbose=0\n",
    "                )\n",
    "\n",
    "                # Executa a busca em grade no subconjunto de treino/validação\n",
    "                # O Pipeline dentro do GridSearchCV garante que o fit() do StandardScaler\n",
    "                # ocorra apenas com os dados de treino de cada fold interno.\n",
    "                grid_search.fit(X_train_val, y_train_val, groups=groups_train_val)\n",
    "\n",
    "                # Avalia o melhor modelo do grid search no conjunto de teste externo\n",
    "                y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "                rmse_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                r2_score_val = r2_score(y_test, y_pred)\n",
    "\n",
    "                test_rmse_scores.append(rmse_score)\n",
    "                test_r2_scores.append(r2_score_val)\n",
    "\n",
    "            # Média e desvio padrão das métricas dos folds externos\n",
    "            mean_rmse = np.mean(test_rmse_scores)\n",
    "            #std_rmse = np.std(test_rmse_scores)\n",
    "            mean_r2 = np.mean(test_r2_scores)\n",
    "            #std_r2 = np.std(test_r2_scores)\n",
    "\n",
    "            print(f\"--- Resultado Final do Nested CV para {model_name} com {feature_set_name} ---\")\n",
    "            print(f\"  > RMSE: {mean_rmse:.4f} +/- {std_rmse:.4f}\")\n",
    "            print(f\"  > R²: {mean_r2:.4f} +/- {std_r2:.4f}\")\n",
    "\n",
    "            final_results.append({\n",
    "                'model': model_name,\n",
    "                'feature_set': feature_set_name,\n",
    "                'mean_rmse': mean_rmse,\n",
    "                'std_rmse': std_rmse,\n",
    "                'mean_r2': mean_r2,\n",
    "                'std_r2': std_r2\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(final_results)\n",
    "\n",
    "\n",
    "# --- Função Principal de Execução ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 1. Carregar os dados\n",
    "    print(\"--- Carregando os dados ---\")\n",
    "    X, y, groups = load_data(\n",
    "        X_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/X-data1-1km.csv',\n",
    "        y_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/y-data1-1km.csv',\n",
    "        groups_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/groups-data1-1km.csv'\n",
    "    )\n",
    "    if X is None:\n",
    "        exit()\n",
    "\n",
    "    print(\"Dados carregados com sucesso.\")\n",
    "\n",
    "    # 2. Executar o Nested CV\n",
    "    print(\"\\n--- Iniciando o Nested Cross-Validation para todos os algoritmos ---\")\n",
    "    results_df = run_nested_cv(\n",
    "        X,\n",
    "        y,\n",
    "        groups,\n",
    "        FEATURE_SETS,\n",
    "        PARAM_GRIDS,\n",
    "        MODELS_TO_RUN\n",
    "    )\n",
    "\n",
    "    # 3. Exibir os resultados finais\n",
    "    print(\"\\n--- Resumo dos Resultados do Nested CV ---\")\n",
    "    display(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8b999f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando os dados ---\n",
      "Dados carregados com sucesso.\n",
      "\n",
      "--- Iniciando o Nested Cross-Validation para todos os algoritmos ---\n",
      "\n",
      "--- Iniciando Nested CV para o modelo: Lasso ---\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS1 ---\n",
      "--- Resultado Final do Nested CV para Lasso com DS1 ---\n",
      "  > RMSE Teste: 0.4523 +/- 0.0392\n",
      "  > RMSE Treino: 0.4017 +/- 0.0055\n",
      "  > R² Teste: 0.7882 +/- 0.0371\n",
      "  > R² Treino: 0.8193 +/- 0.0040\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS2 ---\n",
      "--- Resultado Final do Nested CV para Lasso com DS2 ---\n",
      "  > RMSE Teste: 0.4440 +/- 0.0449\n",
      "  > RMSE Treino: 0.4030 +/- 0.0081\n",
      "  > R² Teste: 0.7959 +/- 0.0386\n",
      "  > R² Treino: 0.8180 +/- 0.0085\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS3 ---\n",
      "--- Resultado Final do Nested CV para Lasso com DS3 ---\n",
      "  > RMSE Teste: 0.4441 +/- 0.0449\n",
      "  > RMSE Treino: 0.4028 +/- 0.0082\n",
      "  > R² Teste: 0.7958 +/- 0.0386\n",
      "  > R² Treino: 0.8182 +/- 0.0087\n",
      "\n",
      "--- Iniciando Nested CV para o modelo: SVR ---\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS1 ---\n",
      "--- Resultado Final do Nested CV para SVR com DS1 ---\n",
      "  > RMSE Teste: 0.4575 +/- 0.0389\n",
      "  > RMSE Treino: 0.3987 +/- 0.0066\n",
      "  > R² Teste: 0.7846 +/- 0.0294\n",
      "  > R² Treino: 0.8216 +/- 0.0069\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS2 ---\n",
      "--- Resultado Final do Nested CV para SVR com DS2 ---\n",
      "  > RMSE Teste: 0.4362 +/- 0.0374\n",
      "  > RMSE Treino: 0.3941 +/- 0.0062\n",
      "  > R² Teste: 0.8038 +/- 0.0287\n",
      "  > R² Treino: 0.8260 +/- 0.0057\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS3 ---\n",
      "--- Resultado Final do Nested CV para SVR com DS3 ---\n",
      "  > RMSE Teste: 0.4405 +/- 0.0387\n",
      "  > RMSE Treino: 0.3931 +/- 0.0066\n",
      "  > R² Teste: 0.7999 +/- 0.0297\n",
      "  > R² Treino: 0.8269 +/- 0.0067\n",
      "\n",
      "--- Iniciando Nested CV para o modelo: DecisionTree ---\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS1 ---\n",
      "--- Resultado Final do Nested CV para DecisionTree com DS1 ---\n",
      "  > RMSE Teste: 0.4843 +/- 0.0221\n",
      "  > RMSE Treino: 0.3440 +/- 0.0164\n",
      "  > R² Teste: 0.7579 +/- 0.0293\n",
      "  > R² Treino: 0.8674 +/- 0.0122\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS2 ---\n",
      "--- Resultado Final do Nested CV para DecisionTree com DS2 ---\n",
      "  > RMSE Teste: 0.4764 +/- 0.0259\n",
      "  > RMSE Treino: 0.3454 +/- 0.0195\n",
      "  > R² Teste: 0.7649 +/- 0.0354\n",
      "  > R² Treino: 0.8653 +/- 0.0166\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS3 ---\n",
      "--- Resultado Final do Nested CV para DecisionTree com DS3 ---\n",
      "  > RMSE Teste: 0.4814 +/- 0.0288\n",
      "  > RMSE Treino: 0.3523 +/- 0.0102\n",
      "  > R² Teste: 0.7598 +/- 0.0374\n",
      "  > R² Treino: 0.8602 +/- 0.0099\n",
      "\n",
      "--- Iniciando Nested CV para o modelo: RandomForest ---\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS1 ---\n",
      "--- Resultado Final do Nested CV para RandomForest com DS1 ---\n",
      "  > RMSE Teste: 0.4085 +/- 0.0358\n",
      "  > RMSE Treino: 0.2669 +/- 0.0097\n",
      "  > R² Teste: 0.8279 +/- 0.0265\n",
      "  > R² Treino: 0.9206 +/- 0.0062\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS2 ---\n",
      "--- Resultado Final do Nested CV para RandomForest com DS2 ---\n",
      "  > RMSE Teste: 0.4067 +/- 0.0375\n",
      "  > RMSE Treino: 0.2698 +/- 0.0217\n",
      "  > R² Teste: 0.8295 +/- 0.0262\n",
      "  > R² Treino: 0.9181 +/- 0.0157\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS3 ---\n",
      "--- Resultado Final do Nested CV para RandomForest com DS3 ---\n",
      "  > RMSE Teste: 0.4094 +/- 0.0409\n",
      "  > RMSE Treino: 0.2685 +/- 0.0188\n",
      "  > R² Teste: 0.8269 +/- 0.0302\n",
      "  > R² Treino: 0.9187 +/- 0.0139\n",
      "\n",
      "--- Iniciando Nested CV para o modelo: XGBoost ---\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS1 ---\n",
      "--- Resultado Final do Nested CV para XGBoost com DS1 ---\n",
      "  > RMSE Teste: 0.3881 +/- 0.0271\n",
      "  > RMSE Treino: 0.2018 +/- 0.0450\n",
      "  > R² Teste: 0.8456 +/- 0.0134\n",
      "  > R² Treino: 0.9514 +/- 0.0177\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS2 ---\n",
      "--- Resultado Final do Nested CV para XGBoost com DS2 ---\n",
      "  > RMSE Teste: 0.3868 +/- 0.0258\n",
      "  > RMSE Treino: 0.2011 +/- 0.0495\n",
      "  > R² Teste: 0.8464 +/- 0.0146\n",
      "  > R² Treino: 0.9514 +/- 0.0197\n",
      "\n",
      "--- Otimizando com o conjunto de features: DS3 ---\n",
      "--- Resultado Final do Nested CV para XGBoost com DS3 ---\n",
      "  > RMSE Teste: 0.3801 +/- 0.0253\n",
      "  > RMSE Treino: 0.2175 +/- 0.0185\n",
      "  > R² Teste: 0.8517 +/- 0.0143\n",
      "  > R² Treino: 0.9461 +/- 0.0089\n",
      "\n",
      "--- Resumo dos Resultados do Nested CV ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>mean_rmse_test</th>\n",
       "      <th>std_rmse_test</th>\n",
       "      <th>mean_rmse_train</th>\n",
       "      <th>std_rmse_train</th>\n",
       "      <th>mean_r2_test</th>\n",
       "      <th>std_r2_test</th>\n",
       "      <th>mean_r2_train</th>\n",
       "      <th>std_r2_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>DS1</td>\n",
       "      <td>0.4523</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>DS2</td>\n",
       "      <td>0.4440</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.4030</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.8180</td>\n",
       "      <td>0.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>DS3</td>\n",
       "      <td>0.4441</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.7958</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.8182</td>\n",
       "      <td>0.0087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR</td>\n",
       "      <td>DS1</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.3987</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.7846</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.8216</td>\n",
       "      <td>0.0069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVR</td>\n",
       "      <td>DS2</td>\n",
       "      <td>0.4362</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.3941</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.8038</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.8260</td>\n",
       "      <td>0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR</td>\n",
       "      <td>DS3</td>\n",
       "      <td>0.4405</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.3931</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.7999</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>0.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>DS1</td>\n",
       "      <td>0.4843</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.3440</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.8674</td>\n",
       "      <td>0.0122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>DS2</td>\n",
       "      <td>0.4764</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.7649</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.8653</td>\n",
       "      <td>0.0166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>DS3</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.3523</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.7598</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.8602</td>\n",
       "      <td>0.0099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>DS1</td>\n",
       "      <td>0.4085</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.2669</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.8279</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.9206</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>DS2</td>\n",
       "      <td>0.4067</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.9181</td>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>DS3</td>\n",
       "      <td>0.4094</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>0.0139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>DS1</td>\n",
       "      <td>0.3881</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.2018</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.8456</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.9514</td>\n",
       "      <td>0.0177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>DS2</td>\n",
       "      <td>0.3868</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.2011</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.9514</td>\n",
       "      <td>0.0197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>DS3</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.8517</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>0.0089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model feature_set  mean_rmse_test  std_rmse_test  mean_rmse_train  \\\n",
       "0          Lasso         DS1          0.4523         0.0392           0.4017   \n",
       "1          Lasso         DS2          0.4440         0.0449           0.4030   \n",
       "2          Lasso         DS3          0.4441         0.0449           0.4028   \n",
       "3            SVR         DS1          0.4575         0.0389           0.3987   \n",
       "4            SVR         DS2          0.4362         0.0374           0.3941   \n",
       "5            SVR         DS3          0.4405         0.0387           0.3931   \n",
       "6   DecisionTree         DS1          0.4843         0.0221           0.3440   \n",
       "7   DecisionTree         DS2          0.4764         0.0259           0.3454   \n",
       "8   DecisionTree         DS3          0.4814         0.0288           0.3523   \n",
       "9   RandomForest         DS1          0.4085         0.0358           0.2669   \n",
       "10  RandomForest         DS2          0.4067         0.0375           0.2698   \n",
       "11  RandomForest         DS3          0.4094         0.0409           0.2685   \n",
       "12       XGBoost         DS1          0.3881         0.0271           0.2018   \n",
       "13       XGBoost         DS2          0.3868         0.0258           0.2011   \n",
       "14       XGBoost         DS3          0.3801         0.0253           0.2175   \n",
       "\n",
       "    std_rmse_train  mean_r2_test  std_r2_test  mean_r2_train  std_r2_train  \n",
       "0           0.0055        0.7882       0.0371         0.8193        0.0040  \n",
       "1           0.0081        0.7959       0.0386         0.8180        0.0085  \n",
       "2           0.0082        0.7958       0.0386         0.8182        0.0087  \n",
       "3           0.0066        0.7846       0.0294         0.8216        0.0069  \n",
       "4           0.0062        0.8038       0.0287         0.8260        0.0057  \n",
       "5           0.0066        0.7999       0.0297         0.8269        0.0067  \n",
       "6           0.0164        0.7579       0.0293         0.8674        0.0122  \n",
       "7           0.0195        0.7649       0.0354         0.8653        0.0166  \n",
       "8           0.0102        0.7598       0.0374         0.8602        0.0099  \n",
       "9           0.0097        0.8279       0.0265         0.9206        0.0062  \n",
       "10          0.0217        0.8295       0.0262         0.9181        0.0157  \n",
       "11          0.0188        0.8269       0.0302         0.9187        0.0139  \n",
       "12          0.0450        0.8456       0.0134         0.9514        0.0177  \n",
       "13          0.0495        0.8464       0.0146         0.9514        0.0197  \n",
       "14          0.0185        0.8517       0.0143         0.9461        0.0089  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importação de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GridSearchCV, GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib # Para salvar o melhor modelo\n",
    "import shap # Mantido para a próxima etapa de análise\n",
    "\n",
    "# --- Definição de Constantes e Hiperparâmetros ---\n",
    "# Conjuntos de features\n",
    "FEATURE_SETS = {\n",
    "    'DS1': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'column_Male', 'age', 'vo2máx'],\n",
    "    'DS2': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed'],\n",
    "    'DS3': ['kilometer', 'wbgt', 'skin_temp', 'heart_rate', 'age', 'column_Male', 'vo2máx', 'speed', 'umidade_absoluta', 'dry_temp', 'wet_temp', 'relative_humidity']\n",
    "}\n",
    "\n",
    "# Grades de hiperparâmetros para cada modelo\n",
    "PARAM_GRIDS = {\n",
    "    'Lasso': {\n",
    "        'model__alpha': np.linspace(0.01, 0.1, 10),\n",
    "    },\n",
    "    'SVR': {\n",
    "        'model__C': [0.1, 1.0, 10.0],\n",
    "        'model__gamma': ['scale', 'auto'],\n",
    "        'model__kernel': ['rbf', 'linear'],\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'model__max_depth': [5, 10, 15],\n",
    "        'model__min_samples_leaf': [1, 5, 8, 10],\n",
    "        'model__min_samples_split': [2, 5, 8, 10],\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model__n_estimators': [100, 200, 400],\n",
    "        'model__max_depth': [5, 10, 15],\n",
    "        'model__min_samples_leaf': [5, 10, 20],\n",
    "        'model__max_features': ['sqrt', 'log2', 0.5, 0.7],\n",
    "        'model__max_samples': [0.7, 0.8, 0.9]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model__n_estimators': [300, 500, 700],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__subsample': [0.5, 0.7, 0.9],\n",
    "        'model__colsample_bytree': [0.5, 0.7, 0.9],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dicionário para mapear os nomes dos modelos para as suas classes\n",
    "MODELS_TO_RUN = {\n",
    "    'Lasso': Lasso(random_state=42, max_iter=20000),\n",
    "    'SVR': SVR(),\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "}\n",
    "\n",
    "# --- Funções para o Fluxo do Modelo ---\n",
    "\n",
    "def load_data(X_path, y_path, groups_path):\n",
    "    \"\"\"\n",
    "    Carrega os dados e realiza uma verificação inicial.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = pd.read_csv(X_path)\n",
    "        y = pd.read_csv(y_path)\n",
    "        groups = pd.read_csv(groups_path)['trial_number']\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro: Arquivo não encontrado - {e.filename}.\")\n",
    "        return None, None, None\n",
    "\n",
    "    # Verificação de valores ausentes\n",
    "    if X.isnull().sum().sum() > 0 or y.isnull().sum().sum() > 0:\n",
    "        print(\"Aviso: Dados contêm valores ausentes (NaN). Considere o pré-processamento para tratá-los.\")\n",
    "\n",
    "    return X, y, groups\n",
    "\n",
    "def run_nested_cv(X, y, groups, feature_sets, param_grids, models_to_run):\n",
    "    \"\"\"\n",
    "    Executa a Validação Cruzada Aninhada para múltiplos modelos,\n",
    "    incluindo a análise de scores de treino para identificar overfitting.\n",
    "    \"\"\"\n",
    "    final_results = []\n",
    "\n",
    "    outer_cv = GroupShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    inner_cv = LeaveOneGroupOut()\n",
    "\n",
    "    for model_name, model_instance in models_to_run.items():\n",
    "        print(f\"\\n--- Iniciando Nested CV para o modelo: {model_name} ---\")\n",
    "\n",
    "        for feature_set_name, feature_list in feature_sets.items():\n",
    "            print(f\"\\n--- Otimizando com o conjunto de features: {feature_set_name} ---\")\n",
    "\n",
    "            # Listas para armazenar as métricas de cada fold externo\n",
    "            test_rmse_scores = []\n",
    "            test_r2_scores = []\n",
    "            train_rmse_scores = [] # Adicionada para os scores de treino\n",
    "            train_r2_scores = [] # Adicionada para os scores de treino\n",
    "\n",
    "            # Cria o pré-processador para o pipeline.\n",
    "            numeric_features = X[feature_list].select_dtypes(include=np.number).columns\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('scaler', StandardScaler(), numeric_features)\n",
    "                ],\n",
    "                remainder='passthrough'\n",
    "            )\n",
    "\n",
    "            if model_name in ['Lasso', 'SVR']:\n",
    "                pipeline = Pipeline([\n",
    "                    ('preprocessor', preprocessor),\n",
    "                    ('model', model_instance)\n",
    "                ])\n",
    "            else:\n",
    "                pipeline = Pipeline([\n",
    "                    ('model', model_instance)\n",
    "                ])\n",
    "\n",
    "            param_grid = param_grids.get(model_name)\n",
    "            if not param_grid:\n",
    "                print(f\"Aviso: Grade de hiperparâmetros não encontrada para {model_name}. Pulando este conjunto.\")\n",
    "                continue\n",
    "\n",
    "            # Loop externo: dividindo o conjunto em treino/validação e teste\n",
    "            for i, (train_val_idx, test_idx) in enumerate(outer_cv.split(X, y, groups=groups)):\n",
    "                # Subconjuntos de dados para o fold atual\n",
    "                X_train_val = X.iloc[train_val_idx][feature_list]\n",
    "                y_train_val = y.iloc[train_val_idx].values.ravel()\n",
    "                groups_train_val = groups.iloc[train_val_idx]\n",
    "\n",
    "                X_test = X.iloc[test_idx][feature_list]\n",
    "                y_test = y.iloc[test_idx].values.ravel()\n",
    "\n",
    "                # Loop interno: GridSearchCV\n",
    "                grid_search = GridSearchCV(\n",
    "                    pipeline,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=inner_cv,\n",
    "                    # Usando a métrica nativa neg_root_mean_squared_error\n",
    "                    # e configurando para salvar os scores de treino\n",
    "                    scoring='neg_root_mean_squared_error',\n",
    "                    return_train_score=True, # Importante: Habilita a coleta de scores de treino\n",
    "                    n_jobs=-1,\n",
    "                    verbose=0\n",
    "                )\n",
    "\n",
    "                # Executa a busca em grade no subconjunto de treino/validação\n",
    "                grid_search.fit(X_train_val, y_train_val, groups=groups_train_val)\n",
    "\n",
    "                # Avalia o melhor modelo no conjunto de teste externo\n",
    "                y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "                rmse_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                r2_score_val = r2_score(y_test, y_pred)\n",
    "\n",
    "                test_rmse_scores.append(rmse_score)\n",
    "                test_r2_scores.append(r2_score_val)\n",
    "\n",
    "                # Acessa os scores de treino e converte de negativo para positivo\n",
    "                best_index = grid_search.best_index_\n",
    "                train_rmse_val = -grid_search.cv_results_['mean_train_score'][best_index]\n",
    "                # Scikit-learn não oferece R² de treino diretamente em cv_results_, então\n",
    "                # para maior rigor, precisaríamos calcular, mas o RMSE já é suficiente para a análise de overfitting.\n",
    "                # Para simplificar, vamos usar uma aproximação.\n",
    "                train_rmse_scores.append(train_rmse_val)\n",
    "                train_r2_scores.append(grid_search.best_estimator_.score(X_train_val, y_train_val))\n",
    "\n",
    "            # Média e desvio padrão das métricas dos folds externos\n",
    "            mean_rmse_test = np.mean(test_rmse_scores)\n",
    "            std_rmse_test = np.std(test_rmse_scores)\n",
    "            mean_r2_test = np.mean(test_r2_scores)\n",
    "            std_r2_test = np.std(test_r2_scores)\n",
    "\n",
    "            mean_rmse_train = np.mean(train_rmse_scores)\n",
    "            std_rmse_train = np.std(train_rmse_scores)\n",
    "            mean_r2_train = np.mean(train_r2_scores)\n",
    "            std_r2_train = np.std(train_r2_scores)\n",
    "\n",
    "            print(f\"--- Resultado Final do Nested CV para {model_name} com {feature_set_name} ---\")\n",
    "            print(f\"  > RMSE Teste: {mean_rmse_test:.4f} +/- {std_rmse_test:.4f}\")\n",
    "            print(f\"  > RMSE Treino: {mean_rmse_train:.4f} +/- {std_rmse_train:.4f}\")\n",
    "            print(f\"  > R² Teste: {mean_r2_test:.4f} +/- {std_r2_test:.4f}\")\n",
    "            print(f\"  > R² Treino: {mean_r2_train:.4f} +/- {std_r2_train:.4f}\")\n",
    "\n",
    "            final_results.append({\n",
    "                'model': model_name,\n",
    "                'feature_set': feature_set_name,\n",
    "                'mean_rmse_test': mean_rmse_test,\n",
    "                'std_rmse_test': std_rmse_test,\n",
    "                'mean_rmse_train': mean_rmse_train,\n",
    "                'std_rmse_train': std_rmse_train,\n",
    "                'mean_r2_test': mean_r2_test,\n",
    "                'std_r2_test': std_r2_test,\n",
    "                'mean_r2_train': mean_r2_train,\n",
    "                'std_r2_train': std_r2_train\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(final_results)\n",
    "\n",
    "\n",
    "# --- Função Principal de Execução ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 1. Carregar os dados\n",
    "    print(\"--- Carregando os dados ---\")\n",
    "    X, y, groups = load_data(\n",
    "        X_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/X-data1-1km.csv',\n",
    "        y_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/y-data1-1km.csv',\n",
    "        groups_path='/home/usuario-leticia/Desktop/Samuel/leticiaag/tcore/data/processed-data/groups-data1-1km.csv'\n",
    "    )\n",
    "    if X is None:\n",
    "        exit()\n",
    "\n",
    "    print(\"Dados carregados com sucesso.\")\n",
    "\n",
    "    # 2. Executar o Nested CV\n",
    "    print(\"\\n--- Iniciando o Nested Cross-Validation para todos os algoritmos ---\")\n",
    "    results_df = run_nested_cv(\n",
    "        X,\n",
    "        y,\n",
    "        groups,\n",
    "        FEATURE_SETS,\n",
    "        PARAM_GRIDS,\n",
    "        MODELS_TO_RUN\n",
    "    )\n",
    "\n",
    "    # 3. Exibir os resultados finais\n",
    "    print(\"\\n--- Resumo dos Resultados do Nested CV ---\")\n",
    "    display(results_df.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d8266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
